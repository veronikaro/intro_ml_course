{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home work 2 \n",
    "\n",
    "[Dataset](https://www.kaggle.com/danielgrijalvas/movies/version/2)\n",
    "\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "1. Preprocessing of dataset, explaination what column do you use, why, In you skip any column explain why. Please analize usage of [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) and/or [TF-IDF Vectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html).You allow to use external sources. \n",
    "2. K-means. Find the best param: number of clusters `n_clusters` (train muptiple models choose the best one). Show that you trained at least two k-means models (train kmeans for dataset with features received by CountVectorizer/TF-IDF Vectorizer and without). The \n",
    "3. Visualize cluster for the best model (2D case, you are allowed to use t-SNE or PCA if you want, not compulsory though)\n",
    "4. DBScan. Find the best params: epsilon `eps` and minimum number of samples `min_samples`(train muptiple models choose the best one). Show that you trained at least two dbscan models (train dbscan for dataset with features received by CountVectorizer/TF-IDF Vectorizer and without)\n",
    "5. Visualize clusters for the best model (2D case, you are allowed to use t-SNE or PCA if you want, not compulsory though)\n",
    "6. Summary for both approaches (describe the model accuracy, performance, score, etc.)\n",
    "\n",
    "## Additional Info\n",
    "\n",
    "Sklearn K-means class has property - `inertia_` sum of squared distances of samples to their closest cluster center. Could be used for comparison.\n",
    "\n",
    "[Here](https://scikit-learn.org/stable/auto_examples/cluster/plot_mini_batch_kmeans.html#sphx-glr-auto-examples-cluster-plot-mini-batch-kmeans-py) is example how you can compare two clustering approaches\n",
    "\n",
    "[Silhouette score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html#sklearn.metrics.silhouette_score)- method of interpretation and validation of consistency within clusters of data [from wiki](https://en.wikipedia.org/wiki/Silhouette_(clustering))\n",
    "\n",
    "t-SNE - method to reduce the dimensionality down to 2 dimenions, check the [kaggle kernel](https://www.kaggle.com/ffisegydd/cluster-analysis-of-movies-data) for example\n",
    "\n",
    "## Submit\n",
    "\n",
    "Two options for submition: via email or on [distedu.ukma.edu.ua](https://distedu.ukma.edu.ua/course/view.php?id=32)\n",
    "\n",
    "You should submit jupyter notebook by Sunday, November 18th till 11:55 pm EEST timezone.\n",
    "\n",
    "\n",
    "## Bonus points\n",
    "\n",
    "Hierarchical clustering. Find best params. Dendogram and explanation.\n",
    "Try all four merge strategies (complete, average, single linkages and ward criteria)\n",
    "(8 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
